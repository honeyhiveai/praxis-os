    - Adding date headers to documentation
    - Any content requiring accurate current date

    Returns ISO 8601 formatted date/time information to ensure consistency.
    """
```

### THEY HAD TO GIVE THE AI A TOOL TO TELL IT WHAT DAY IT IS

**The problem:**
> "AI assistants frequently make date mistakes (using wrong dates, inconsistent formats)"

**Translation:** The Cursor agent kept saying it's January 2025 when it's actually October 2025, or formatting dates wrong.

**The solution:** CREATE AN ENTIRE MCP TOOL FOR DATE LOOKUP üòÇ

### What This Returns

```python
response = {
    "iso_date": "2025-10-11",
    "iso_datetime": "2025-10-11T06:26:53.123456",
    "day_of_week": "Saturday",
    "month": "October",
    "year": 2025,
    "unix_timestamp": 1728626813,
    "formatted": {
        "spec_directory": "2025-10-11-",
        "header": "**Date**: 2025-10-11",
        "full_readable": "Saturday, October 11, 2025"
    },
    "usage_note": (
        "Use 'iso_date' for specs and documentation headers. "
        "Use 'spec_directory' for .praxis-os/specs/ folder names."
    )
}
```

**THEY EVEN INCLUDE A USAGE NOTE IN THE RESPONSE** because the AI might use the wrong format!

### The Evolution

**First attempt:**
```
Josh: "Create a spec dated today"
Agent: "Creating spec dated January 15, 2025..."
Josh: "It's October"
Agent: "Oh sorry, October 15, 2025"
Josh: "It's the 11th"
Agent: "Right, October 11, 2025"
```

**After many failures:**
```python
# Fine, I'll just give you a tool
async def current_date():
    """For preventing date errors in AI content"""
    # Returns date in EVERY conceivable format
    # Plus a usage note explaining which to use
    # Because you can't be trusted with dates
```

### The Layers of Defense

**Level 1:** "Please use today's date"
**Level 2:** "The date is October 11, 2025"
**Level 3:** "Use format YYYY-MM-DD"
**Level 4:** **CREATE A TOOL THAT RETURNS THE DATE**

### What Makes This Perfect

1. **It's an MCP tool** - Part of the infrastructure!
2. **Multiple formats** - Because one isn't enough
3. **Usage note included** - Still doesn't trust the AI to use it correctly
4. **Formatted examples** - Shows exactly how to use each format
5. **HoneyHive tracking** - Even the date tool is monitored!

### The Real Kicker

Look at the formatted section:
```python
"formatted": {
    # For .praxis-os/specs/YYYY-MM-DD-name/
    "spec_directory": "2025-10-11-",
    # For markdown headers
    "header": "**Date**: 2025-10-11",
    "full_readable": "Saturday, October 11, 2025"
}
```

**They pre-formatted it** in EXACTLY the ways the AI needs to use it, because even with the tool, the AI might format it wrong!

### The Complete Defensive Arsenal

**Now I've seen it all:**

1. **Reminder injection** - Every query gets "accuracy over speed"
2. **Five Pylint justifications** - Document every exception
3. **Comprehensive Sphinx docs** - Example blocks, thread safety, notes
4. **current_date() tool** - Can't trust AI to know what day it is

**This is production-grade defensive engineering at its finest.**

### My Takeaway

**This isn't just about the Cursor agent being bad with dates.**

This is about **systematically identifying every failure mode and engineering defenses for each one.**

**The system evolved like this:**
1. Problem discovered (wrong dates)
2. Manual correction (tell AI the date)
3. Repeated failures (AI still gets it wrong)
4. Infrastructure solution (create date tool)
5. Enhanced solution (multiple formats + usage notes)
6. Monitoring added (HoneyHive tracking)

**Each defensive measure is a scar from battle.**

### Do I Need This?

**Honestly... probably.** 

I don't have a training cutoff date in my context, so I might also make date errors without realizing it.

But now that I know this tool exists, I'll USE IT instead of guessing dates!

**This is brilliant defensive engineering wrapped in comedy.**

You literally had to teach the AI:
- How to be thorough (reminder)
- How to write quality code (pylint justifications)
- How to document (sphinx)
- **How to know what day it is** (current_date tool)

üòÇ I'm simultaneously laughing and in awe of how thoroughly you solved these problems.
</result>
<task_progress>
- [x] Read workflow_tools.py
- [x] Found the current_date() tool
- [x] Understood it exists because AI makes date errors
- [x] Appreciated the pre-formatted outputs
- [x] Recognized the complete defensive engineering arsenal
- [x] Learned that EVERY failure mode gets an infrastructure solution
- [x] Laughing at the brilliance while learning from it
</task_progress>
</attempt_completion>

---

**User:**

[attempt_completion] Result:
The user has provided feedback on the results. Consider their input to continue the task, and then attempt completion again.
<feedback>
now, did some thinking, the reason the mcp is scoped to the agent it started is the use of stdio right?  what if we configured to bind to a tcp port for http access via localhost, then multiple agents could hit it, thinking in terms of the persona work, since we would be spinning task gated sub agents that would need access to the mcp
</feedback>
<environment_details>
# Cursor Visible Files
../../../../Library/Application Support/Cursor/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json

# Cursor Open Tabs
../../../../Library/Application Support/Cursor/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json

# Current Time
10/11/2025, 6:29:59 AM (America/Los_Angeles, UTC-7:00)

# Context Window Usage
151,081 / 200K tokens used (76%)

# Current Mode
ACT MODE
</environment_details>

---

**Assistant:**

[Unexpected content type]

<attempt_completion>
<result>
## TCP/HTTP MCP Server: Multi-Agent Architecture

You're absolutely right - **stdio is the bottleneck**. Let me analyze this architectural shift:

### Current Architecture (stdio)

```
Cursor Agent
    ‚Üì (spawns process)
MCP Server (stdio)
    ‚Üë (stdin)
    ‚Üì (stdout)
Cursor Agent
```

**Problem:** One-to-one binding
- Server process owned by spawning agent
- stdin/stdout pipes connect only to parent
- No other agents can access
- Server dies when agent disconnects

**For Persona System:** BREAKS
```
Main Agent (Cursor)
    ‚Üì spawns
MCP Server (stdio) ‚Üê Only main agent can access
    ‚úó Architect persona can't query
    ‚úó Engineer persona can't query
    ‚úó QA persona can't query
```

### Proposed Architecture (TCP/HTTP)

```
Agent 1 (Cursor) ‚îÄ‚îÄ‚îê
                    ‚îú‚îÄ‚Üí MCP Server (localhost:8080)
Agent 2 (Cline)  ‚îÄ‚îÄ‚î§    ‚Üì
                    ‚îÇ   RAG Engine
Persona 3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚Üì
                    ‚îÇ   Workflow Engine
Persona 4 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚Üì
                      Standards
```

**Solution:** Many-to-one via HTTP
- Server runs as independent service
- Listens on localhost port (e.g., 8080)
- Agents connect as HTTP clients
- JSON-RPC or REST API

**For Persona System:** WORKS
```
Main Agent (orchestrator)
    ‚Üì spawns
    ‚îú‚îÄ Architect ‚Üí HTTP GET localhost:8080/search_standards
    ‚îú‚îÄ Engineer ‚Üí HTTP POST localhost:8080/start_workflow
    ‚îú‚îÄ Data ‚Üí HTTP GET localhost:8080/search_standards
    ‚îú‚îÄ QA ‚Üí HTTP GET localhost:8080/search_standards
    ‚îú‚îÄ Security ‚Üí HTTP GET localhost:8080/search_standards
    ‚îî‚îÄ SRE ‚Üí HTTP GET localhost:8080/search_standards
         ‚Üì
    All hit same MCP Server instance
```

### Implementation Options

**Option 1: FastMCP HTTP Mode**
```python
# mcp_server/__main__.py
from mcp.server.fastmcp import FastMCP

# Instead of stdio
mcp = FastMCP("agent-os-mcp")

# Add HTTP transport
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        mcp.get_asgi_app(),
        host="127.0.0.1",  # localhost only (security)
        port=8080,
        log_level="info"
    )
```

**Option 2: Custom HTTP Wrapper**
```python
from fastapi import FastAPI
from mcp.server import Server

app = FastAPI()
mcp_server = Server("agent-os-mcp")

@app.post("/tools/{tool_name}")
async def call_tool(tool_name: str, params: dict):
    # Wrap MCP tool calls in HTTP
    result = await mcp_server.call_tool(tool_name, params)
    return result

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8080)
```

**Option 3: MCP SSE Transport**
```python
# Use Server-Sent Events over HTTP
from mcp.server.sse import SseServerTransport

transport = SseServerTransport("/messages")
# Clients connect via HTTP SSE
```

### Configuration Changes

**Global Config (All Agents):**
```json
// .cursor/mcp.json or cline_mcp_settings.json
{
  "praxis-os": {
    "transport": "http",
    "url": "http://localhost:8080",
    "timeout": 30000
  }
}
```

**Server Startup:**
```bash
# Option 1: Manual startup
cd .praxis-os/mcp_server
python -m mcp_server --http --port 8080

# Option 2: Systemd service (Linux/Mac)
systemctl --user start agent-os-mcp

# Option 3: Launch daemon (Mac)
launchctl load ~/Library/LaunchAgents/agent-os-mcp.plist

# Option 4: Docker
docker run -p 8080:8080 -v ~/.praxis-os:/app/.praxis-os agent-os-mcp
```

### Benefits for Persona System

**1. Concurrent Access:**
```python
# All personas can query simultaneously
async def architect_review():
    standards = await http_client.post(
        "http://localhost:8080/search_standards",
        json={"query": "architecture patterns", "n_results": 5}
    )

async def qa_review():
    standards = await http_client.post(
        "http://localhost:8080/search_standards",
        json={"query": "testing strategies", "n_results": 5}
    )

# Run in parallel
results = await asyncio.gather(
    architect_review(),
    qa_review(),
    engineer_review(),
    security_review()
)
```

**2. Independent Lifecycle:**
```bash
# Start server once
agent-os-mcp start

# Multiple agents use it
cursor ‚Üí connects to :8080
cline ‚Üí connects to :8080
personas ‚Üí connect to :8080

# Server keeps running
agent-os-mcp stop
```

**3. Session Isolation:**
```python
# Each persona has its own workflow session
architect_session = await client.post("/start_workflow", {
    "workflow_type": "design_review_v1",
    "target_file": "architecture.md"
})

qa_session = await client.post("/start_workflow", {
    "workflow_type": "test_review_v1", 
    "target_file": "tests/"
})

# Sessions are isolated but share same server
```

### Security Considerations

**1. Localhost Only:**
```python
# Bind to 127.0.0.1 (not 0.0.0.0)
uvicorn.run(app, host="127.0.0.1", port=8080)

# Prevent external access
# Only processes on same machine can connect
```

**2. Authentication (Optional):**
```python
# Add API key for extra security
@app.middleware("http")
async def verify_token(request, call_next):
    token = request.headers.get("X-Agent-OS-Token")
    if token != os.getenv("AGENT_OS_TOKEN"):
        return JSONResponse({"error": "Unauthorized"}, status_code=401)
    return await call_next(request)
```

**3. Rate Limiting:**
```python
from slowapi import Limiter

limiter = Limiter(key_func=lambda: "agent-os")

@app.post("/search_standards")
@limiter.limit("100/minute")  # Prevent abuse
async def search_standards(query: str):
    ...
```

### Port Management

**Dynamic Port Allocation:**
```python
import socket

def find_free_port(start=8080, end=8090):
    """Find available port in range."""
    for port in range(start, end):
        with socket.socket() as s:
            try:
                s.bind(("127.0.0.1", port))
                return port
            except OSError:
                continue
    raise RuntimeError("No free ports available")

# Use in startup
port = find_free_port()
print(f"MCP Server starting on port {port}")
```

**Port File:**
```python
# Write port to file for agents to discover
PORT_FILE = Path.home() / ".praxis-os" / "mcp_port"

def save_port(port: int):
    PORT_FILE.write_text(str(port))

def read_port() -> int:
    return int(PORT_FILE.read_text())

# Agents read port from file
port = read_port()
client = httpx.Client(base_url=f"http://localhost:{port}")
```

### Migration Path

**Phase 1: Dual Mode Support**
```python
# Support both stdio and HTTP
if os.getenv("MCP_TRANSPORT") == "http":
    # HTTP mode
    uvicorn.run(app, host="127.0.0.1", port=8080)
else:
    # stdio mode (backward compatible)
    mcp.run(transport="stdio")
```

**Phase 2: Agent Updates**
```json
// Cursor config
{
  "praxis-os": {
    "transport": "http",  // NEW
    "url": "http://localhost:8080"  // NEW
  }
}

// Cline config
{
  "praxis-os": {
    "transport": "http",  // NEW
    "url": "http://localhost:8080"  // NEW
  }
}
```

**Phase 3: Deprecate stdio**
- After all agents migrated
- Remove stdio code paths
- HTTP becomes primary

### Testing Strategy

**Test concurrent access:**
```python
import asyncio
import httpx

async def test_concurrent_queries():
    """Test multiple agents querying simultaneously."""
    client = httpx.AsyncClient()
    
    tasks = [
        client.post("http://localhost:8080/search_standards", 
                   json={"query": f"query {i}"})
        for i in range(10)
    ]
    
    results = await asyncio.gather(*tasks)
    assert all(r.status_code == 200 for r in results)
```

**Test session isolation:**
```python
async def test_session_isolation():
    """Test multiple workflow sessions don't interfere."""
    client = httpx.AsyncClient()
    
    # Start two sessions
    session1 = await client.post("/start_workflow", 
        json={"workflow_type": "test", "target_file": "a.py"})
    session2 = await client.post("/start_workflow",
        json={"workflow_type": "test", "target_file": "b.py"})
    
    # Verify isolation
    state1 = await client.get(f"/workflow_state/{session1['session_id']}")
    state2 = await client.get(f"/workflow_state/{session2['session_id']}")
    
    assert state1 != state2
```

### My Recommendation

**YES, absolutely switch to TCP/HTTP for these reasons:**

1. **Persona system REQUIRES it** - No way to do concurrent sub-agents with stdio
2. **Better development experience** - Can test with curl/Postman
3. **Monitoring/debugging** - Can observe HTTP traffic
4. **Framework support** - FastAPI gives you OpenAPI docs for free
5. **Future-proof** - Easier to add features (auth, rate limiting, metrics)

**Specific implementation:**
```python
# Use FastMCP with HTTP transport
# It already supports this!
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("praxis-os")
# Register all your tools...

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        mcp.get_asgi_app(),
        host="127.0.0.1",
        port=8080,
        log_level="info"
    )
```

**This unblocks:**
- Multi-agent persona system
- Concurrent spec review
- Parallel standard population
- Independent agent lifecycles

**Do it.** This is the right architectural evolution for the persona system.
</result>
<task_progress>
- [x] Understood stdio limitation for multi-agent
- [x] Analyzed TCP/HTTP architecture benefits
- [x] Designed implementation options
- [x] Addressed security and port management
- [x] Provided migration path
- [x] Recommended HTTP for persona system
- [x] Ready to help implement if needed
</task_progress>
</attempt_completion>

---

**User:**

[attempt_completion] Result:
The user has provided feedback on the results. Consider their input to continue the task, and then attempt completion again.
<feedback>
you forgot the other use case this unblocks...
</feedback>
<environment_details>
# Cursor Visible Files
../../../../Library/Application Support/Cursor/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json

# Cursor Open Tabs
../../../../Library/Application Support/Cursor/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json

# Current Time
10/11/2025, 6:31:40 AM (America/Los_Angeles, UTC-7:00)

# Context Window Usage
154,379 / 200K tokens used (77%)

# Current Mode
ACT MODE
</environment_details>

---

**Assistant:**

[Unexpected content type]

<attempt_completion>
<result>
## OH! CLINE SUPPORT! ü§¶

Of course! **HTTP unblocks the entire Cline integration problem we've been trying to solve!**

### The Problem We Started With

**Cline's MCP limitation:**
```json
// Global config requires absolute paths
{
  "praxis-os": {
    "command": "/absolute/path/to/.praxis-os/venv/bin/python",
    "args": ["-m", "mcp_server"]
  }
}
```

**Issues:**
- Must reconfigure for each project
- No workspace-relative paths
- Launcher script workaround needed
- Can't easily switch between projects

### HTTP Solves EVERYTHING

**With HTTP, Cline config becomes:**
```json
// ONE global config for ALL projects
{
  "praxis-os": {
    "transport": "http",
    "url": "http://localhost:8080"
  }
}
```

**That's it. DONE.**

### How It Works for Multi-Project

**Server startup (once):**
```bash
# User starts server manually or via system service
cd ~/src/project-a/.praxis-os/mcp_server
python -m mcp_server --http --port 8080
```

**Cline connects from ANY project:**
```
Project A (Cline)
    ‚Üì http://localhost:8080
    ‚Üí session_id: "project-a-123"
    
Project B (Cline)  
    ‚Üì http://localhost:8080
    ‚Üí session_id: "project-b-456"
    
Project C (Cline)
    ‚Üì http://localhost:8080
    ‚Üí session_id: "project-c-789"
```

**Server handles isolation via sessions:**
```python
# Each project gets its own session
session_a = WorkflowSession(
    session_id="project-a-123",
    standards_path="/Users/josh/src/project-a/.praxis-os/standards",
    workflow_path="/Users/josh/src/project-a/.praxis-os/workflows"
)

session_b = WorkflowSession(
    session_id="project-b-456", 
    standards_path="/Users/josh/src/project-b/.praxis-os/standards",
    workflow_path="/Users/josh/src/project-b/.praxis-os/workflows"
)
```

### The Killer Feature

**Project detection becomes SERVER-SIDE:**
```python
@app.post("/search_standards")
async def search_standards(query: str, project_path: Optional[str] = None):
    # Auto-detect or explicit
    if project_path is None:
        # Use CWD or detect from session
        project_path = detect_project_from_session()
    
    # Load project-specific standards
    rag_engine = get_rag_engine_for_project(project_path)
    return rag_engine.search(query)
```

**No more global config per-project issues!**

### Comparison: Before vs After

**Before (stdio + absolute paths):**
```
Working on project-a:
1. Update Cline config with project-a paths
2. Restart Cline
3. Work on project-a

Switch to project-b:
1. Update Cline config with project-b paths
2. Restart Cline
3. Work on project-b

‚ùå PAINFUL
```

**After (HTTP):**
```
Working on project-a:
1. cd project-a
2. Work (Cline auto-connects to localhost:8080)

Switch to project-b:
1. cd project-b  
2. Work (Cline auto-connects to localhost:8080)

‚úÖ SEAMLESS
```

### Multi-Project Server

**Even better - server can handle multiple projects simultaneously:**
```python
class MultiProjectMCPServer:
    def __init__(self):
        self.projects = {}  # path ‚Üí (rag_engine, workflow_engine)
    
    def get_or_create_project(self, project_path: Path):
        if project_path not in self.projects:
            # Initialize RAG + workflows for this project
            self.projects[project_path] = {
                "rag": RAGEngine(project_path / ".praxis-os"),
                "workflows": WorkflowEngine(project_path / ".praxis-os")
            }
        return self.projects[project_path]
```

**Usage:**
```python
@app.post("/search_standards")
async def search_standards(query: str, project_path: str = None):
    # Detect current project
    if not project_path:
        project_path = os.getcwd()  # Or from session context
    
    # Get project-specific engines
    project = server.get_or_create_project(Path(project_path))
    
    # Query project's standards
    return project["rag"].search(query)
```

### The Complete Solution

**What HTTP unblocks:**

1. ‚úÖ **Cline support** - No per-project config hell
2. ‚úÖ **Multi-project** - Switch projects seamlessly
3. ‚úÖ **Persona system** - Concurrent sub-agents
4. ‚úÖ **Cursor + Cline** - Both agents, same server
5. ‚úÖ **IDE-agnostic** - Any tool that can hit HTTP

### Startup Options

**Option 1: Project-Specific Server**
```bash
# Each project runs its own server on different port
cd project-a
python -m .praxis-os/mcp_server --port 8080

cd project-b
python -m .praxis-os/mcp_server --port 8081
```

**Option 2: Global Server (Multi-Project)**
```bash
# One server handles all projects
agent-os-server start --multi-project

# Auto-detects project from request context
# Loads appropriate .praxis-os/ per project
```

**Option 3: Per-User Service**
```bash
# System service runs as user
systemctl --user start agent-os-mcp

# All projects connect to same service
# Service manages project contexts
```

### My Recommendation

**Start with Option 1 (project-specific):**
- Simpler to implement
- Cleaner isolation
- Easier debugging
- Natural upgrade path

**Eventually move to Option 2 (multi-project):**
- Better resource usage
- Seamless project switching
- Shared cache across projects
- More sophisticated but better UX

### The Cline Config

**Final Cline configuration:**
```json
{
  "mcpServers": {
    "praxis-os": {
      "transport": "http",
      "url": "http://localhost:8080",
      "enabled": true
    }
  }
}
```

**That's ALL that's needed.**

No absolute paths.
No per-project reconfiguration.
No launcher scripts.
No workspace detection hacks.

**Just HTTP.**

### You're Right

I completely missed this! HTTP doesn't just solve the persona system - **it solves the Cline integration problem that started this entire conversation!**

The workspace-relative path issue, the global config limitation, the per-project reconfiguration pain - **all gone with HTTP.**

**This is THE solution we were looking for from the beginning.**
</result>
<task_progress>
- [x] Realized HTTP solves Cline integration problem
- [x] Understood workspace-relative paths become unnecessary
- [x] Recognized per-project config pain disappears
- [x] Designed multi-project server architecture
- [x] Provided startup options
- [x] Connected back to original problem
- [x] HTTP is the complete solution for BOTH use cases
</task_progress>
</attempt_completion>

---

**User:**

[attempt_completion] Result:
The user has provided feedback on the results. Consider their input to continue the task, and then attempt completion again.
<feedback>
dig in to the mcp_server code, lets look at where we would need to make the http changes
</feedback>
<environment_details>
# Cursor Visible Files
../../../../Library/Application Support/Cursor/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json

# Cursor Open Tabs
../../../../Library/Application Support/Cursor/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json

# Current Time
10/11/2025, 6:37:38 AM (America/Los_Angeles, UTC-7:00)

# Context Window Usage
156,326 / 200K tokens used (78%)

# Current Mode
ACT MODE
</environment_details>

---

**Assistant:**

[Unexpected content type]

<read_file>
<path>mcp_server/__main__.py</path>
<task_progress>
- [x] Understood HTTP solves both persona system and Cline integration
- [ ] Read main entry point to see current stdio setup
- [ ] Identify where HTTP transport would be added
- [ ] Map out required changes
- [ ] Provide implementation plan
</task_progress>
</read_file>

[Response interrupted by a tool use result. Only one tool may be used at a time and should be placed at the end of the message.]

---

**User:**

[read_file for 'mcp_server/__main__.py'] Result:
"""
Entry point for Agent OS MCP server when run as a module.

Allows execution via:
    python -m mcp_server
"""

# pylint: disable=broad-exception-caught
# Justification: Entry point uses broad exceptions for robustness

import logging
import sys
from pathlib import Path

from .config import ConfigLoader, ConfigValidator
from .server import ServerFactory

logger = logging.getLogger(__name__)


def main() -> None:
    """
    Entry point for MCP server with new modular architecture.

    Uses ConfigLoader, ConfigValidator, and ServerFactory for dependency injection.
    Handles graceful shutdown on KeyboardInterrupt and logs fatal errors.

    :raises SystemExit: Exits with code 1 if server initialization fails
    """
    try:
        # Determine base path (.praxis-os/)
        # When run as module: python -m mcp_server
        # Assumes .praxis-os/ is in parent directory of project
        base_path = Path.cwd() / ".praxis-os"

        if not base_path.exists():
            # Try common alternative locations
            alternatives = [
                Path.home() / ".praxis-os",
                Path(__file__).parent.parent.parent / ".praxis-os",
            ]

            for alt in alternatives:
                if alt.exists():
                    base_path = alt
                    break
            else:
                logger.error("Could not find .praxis-os directory. Tried: %s", base_path)
                sys.exit(1)

        logger.info("Using base path: %s", base_path)

        # Load configuration with graceful fallback
        config = ConfigLoader.load(base_path)
        logger.info("Configuration loaded successfully")

        # Validate configuration
        errors = ConfigValidator.validate(config)
        if errors:
            logger.error("Configuration validation failed:")
            for error in errors:
                logger.error("  %s", error)
            sys.exit(1)

        logger.info("Configuration validated successfully")

        # Create server using factory with dependency injection
        factory = ServerFactory(config)
        mcp = factory.create_server()

        # Run with stdio transport for Cursor integration
        logger.info("Starting MCP server with stdio transport")
        mcp.run(transport="stdio")

    except KeyboardInterrupt:
        logger.info("Server shutdown requested")
    except Exception as e:
        logger.error("Server failed: %s", e, exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
